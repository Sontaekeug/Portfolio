import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import tkinter as tk
from tkinter import ttk, scrolledtext
from datetime import datetime
from konlpy.tag import Okt
import json
import threading
import queue
import os
import pickle
import re
from sklearn.metrics import precision_recall_fscore_support

class EmotionAnalysisModel(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):
        super().__init__()
        # ì„ë² ë”© ë ˆì´ì–´ ì„¤ì •
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.embedding_dropout = nn.Dropout(0.2)  # ë“œë¡­ì•„ì›ƒ ê°’ ì„¤ì •
        
        # CNN ë ˆì´ì–´ ì„¤ì •
        self.conv_layers = nn.ModuleList([
            nn.Conv1d(embedding_dim, hidden_dim, kernel_size=k, padding=k//2)
            for k in [3, 4, 5]
        ])
        
        # LSTM ë ˆì´ì–´ ì„¤ì •
        self.lstm = nn.LSTM(
            hidden_dim * 3,  # 3ê°œì˜ ì»¨ë³¼ë£¨ì…˜ ê²°ê³¼ë¥¼ ì—°ê²°
            hidden_dim,
            num_layers=2,
            bidirectional=True,
            dropout=0.3,
            batch_first=True
        )
        
        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ ì„¤ì •
        self.attention = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.LeakyReLU(),  # ReLU ëŒ€ì‹  LeakyReLU ì‚¬ìš© 0 ì´í•˜ ê°’ ê¸°ìš¸ê¸° ê°’ ì ìš©(* 0.1)
            nn.Linear(hidden_dim, 1),
            nn.Softmax(dim=1)
        )
        
        # ì¶œë ¥ ë ˆì´ì–´
        self.dropout = nn.Dropout(0.3)  # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ ì¡°ì •
        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)
        self.leaky_relu = nn.LeakyReLU()
        self.batch_norm = nn.BatchNorm1d(hidden_dim)  # ë°°ì¹˜ ì •ê·œí™” ì¶”ê°€
        self.fc2 = nn.Linear(hidden_dim, output_dim)
        
    def forward(self, text):
        # ì„ë² ë”©
        embedded = self.embedding(text)
        embedded = self.embedding_dropout(embedded)
        
        # CNN ì²˜ë¦¬
        conv_input = embedded.transpose(1, 2)
        conv_outputs = []
        for conv in self.conv_layers:
            conv_out = self.leaky_relu(conv(conv_input))
            pooled = F.max_pool1d(conv_out, conv_out.shape[2]).squeeze(2)
            conv_outputs.append(pooled)
        
        conv_output = torch.cat(conv_outputs, dim=1)
        conv_output = conv_output.unsqueeze(1).repeat(1, embedded.size(1), 1)
        
        # LSTM ì²˜ë¦¬
        lstm_out, _ = self.lstm(conv_output)
        
        # ì–´í…ì…˜ ì ìš©
        attention_weights = self.attention(lstm_out)
        attention_output = torch.bmm(lstm_out.transpose(1, 2), attention_weights).squeeze(-1)
        
        # ìµœì¢… ì¶œë ¥
        output = self.dropout(attention_output)
        output = self.fc1(output)
        output = self.leaky_relu(output)
        output = self.batch_norm(output)
        output = self.dropout(output)
        output = self.fc2(output)
        
        return output

def load_initial_training_data():
    """ì´ˆê¸° í•™ìŠµ ë°ì´í„°"""
    return [
        # ê¸ì •ì ì¸ ë¬¸ì¥ (20ê°œ)
        ("ì˜¤ëŠ˜ ì •ë§ í–‰ë³µí•œ í•˜ë£¨ì˜€ì–´!", 0),
        ("ì‹œí—˜ ê²°ê³¼ê°€ ë„ˆë¬´ ì¢‹ì•„ì„œ ê¸°ë¶„ì´ ìµœê³ ì•¼!", 0),
        ("ë“œë””ì–´ í”„ë¡œì íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë§ˆì³¤ë‹¤!", 0),
        ("ìƒˆë¡œìš´ ì¹œêµ¬ë¥¼ ì‚¬ê·€ì–´ì„œ ë„ˆë¬´ ì¦ê±°ì›Œ", 0),
        ("ê¸¸ì—ì„œ ìš°ì—°íˆ ì˜› ì¹œêµ¬ë¥¼ ë§Œë‚˜ì„œ ë°˜ê°€ì› ì–´", 0),
        ("ìŠ¹ì§„ ì†Œì‹ì„ ë“¤ì–´ì„œ ì •ë§ ê¸°ì˜ë„¤ìš”", 0),
        ("ì˜¤ëœë§Œì— ê°€ì¡±ë“¤ê³¼ ì¢‹ì€ ì‹œê°„ì„ ë³´ëƒˆì–´ìš”", 0),
        ("ì—´ì‹¬íˆ ì¤€ë¹„í•œ ë°œí‘œê°€ ëŒ€ì„±ê³µì´ì—ˆì–´!", 0),
        ("ì²« ì›”ê¸‰ì„ ë°›ì•„ì„œ ë„ˆë¬´ ì„¤ë ˆìš”", 0),
        ("ìš´ë™ì„ ì‹œì‘í•œ ë’¤ë¡œ ëª¸ì´ ì •ë§ ê±´ê°•í•´ì§„ ê²ƒ ê°™ì•„", 0),
        ("ìƒˆë¡œ ì‚° ì˜·ì´ ë„ˆë¬´ ë§ˆìŒì— ë“¤ì–´", 0),
        ("ì˜¤ëŠ˜ ìš”ë¦¬í•œ ìŒì‹ì´ ì •ë§ ë§›ìˆê²Œ ëì–´", 0),
        ("ì—¬í–‰ ê³„íšì´ ë‹¤ ì§œì—¬ì„œ ë„ˆë¬´ ì‹ ë‚˜!", 0),
        ("ì†Œì›í•˜ë˜ ì¼ì´ ì´ë£¨ì–´ì ¸ì„œ ê°ê²©ìŠ¤ëŸ¬ì›Œìš”", 0),
        ("ë´‰ì‚¬í™œë™ì„ í•˜ê³  ë‚˜ë‹ˆ ë§ˆìŒì´ ë”°ëœ»í•´ì¡Œì–´ìš”", 0),
        ("ì¢‹ì•„í•˜ëŠ” ê°€ìˆ˜ì˜ ì½˜ì„œíŠ¸ í‹°ì¼“ì„ êµ¬í–ˆì–´!", 0),
        ("ë“œë””ì–´ ìê²©ì¦ ì‹œí—˜ì— í•©ê²©í–ˆë‹¤!", 0),
        ("ìƒˆë¡œìš´ ì·¨ë¯¸ë¥¼ ì°¾ì•„ì„œ ë„ˆë¬´ ì¦ê±°ì›Œ", 0),
        ("ì˜¤ëœë§Œì— ë§›ìˆëŠ” ì‹ì‚¬ë¥¼ í–ˆë„¤ìš”", 0),
        ("ì˜ˆìœ ì¹´í˜ë¥¼ ë°œê²¬í•´ì„œ ê¸°ë¶„ì´ ì¢‹ì•„ìš”", 0),

        # ë¶€ì •ì ì¸ ë¬¸ì¥ (20ê°œ)
        ("ì˜¤ëŠ˜ ì •ë§ ìµœì•…ì˜ í•˜ë£¨ì˜€ì–´...", 2),
        ("ì‹œí—˜ì„ ë§ì³ì„œ ë„ˆë¬´ ì†ìƒí•˜ë‹¤", 2),
        ("ì¤‘ìš”í•œ ì•½ì†ì— ì§€ê°í•´ì„œ ë¯¸ì•ˆí•´...", 2),
        ("ì¹œêµ¬ì™€ ì‹¬í•˜ê²Œ ë‹¤í‰ˆì„œ ë§ˆìŒì´ ì•„íŒŒìš”", 2),
        ("í”„ë¡œì íŠ¸ ë§ˆê°ì¼ì— ë§ì¶”ì§€ ëª»í–ˆì–´", 2),
        ("ì‹¤ìˆ˜ë¡œ ì¤‘ìš”í•œ íŒŒì¼ì„ ì‚­ì œí–ˆì–´...", 2),
        ("ëª¸ì´ ì•„íŒŒì„œ ë³‘ì›ì— ê°€ì•¼í•  ê²ƒ ê°™ì•„", 2),
        ("ë©´ì ‘ì—ì„œ ë–¨ì–´ì ¸ì„œ ë„ˆë¬´ ì‹¤ë§ìŠ¤ëŸ¬ì›Œ", 2),
        ("ë¹„ê°€ ì™€ì„œ ê³„íšì´ ë‹¤ ë§ì³ì¡Œì–´", 2),
        ("ì§€ê°‘ì„ ìƒì–´ë²„ë ¤ì„œ ì •ë§ ì†ìƒí•´", 2),
        ("ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë„ˆë¬´ ì‹¬í•´ì„œ í˜ë“¤ì–´ìš”", 2),
        ("ì¹œí•œ ì¹œêµ¬ê°€ ì´ì‚¬ë¥¼ ê°€ì„œ ìŠ¬í¼ìš”", 2),
        ("ì‹¤ìˆ˜ë¡œ í°ì„ ë–¨ì–´ëœ¨ë ¤ì„œ í™”ë©´ì´ ê¹¨ì¡Œì–´", 2),
        ("ë²„ìŠ¤ë¥¼ ë†“ì³ì„œ íšŒì˜ì— ëŠ¦ì—ˆì–´ìš”", 2),
        ("ì¢‹ì•„í•˜ëŠ” ìŒì‹ì ì´ ë¬¸ì„ ë‹«ì•˜ì–´ìš”", 2),
        ("ì¤‘ìš”í•œ ë°œí‘œë¥¼ ë§ì³ì„œ ìì±…ê°ì´ ë“¤ì–´ìš”", 2),
        ("ì• ì¸ê³¼ í—¤ì–´ì ¸ì„œ ë„ˆë¬´ í˜ë“¤ì–´ìš”", 2),
        ("ì§‘ì—ì„œ í‚¤ìš°ë˜ ë°˜ë ¤ë™ë¬¼ì´ ì•„íŒŒìš”", 2),
        ("ì›”ê¸‰ì´ ìƒê°ë³´ë‹¤ ë„ˆë¬´ ì ì–´ì„œ ì‹¤ë§í–ˆì–´ìš”", 2),
        ("íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ë¬´ì„ìŠ¹ì°¨í•˜ëŠ” ë™ë£Œ ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„ìš”", 2),

        # ì¤‘ë¦½ì ì¸ ë¬¸ì¥ (20ê°œ)
        ("ì˜¤ëŠ˜ ë‚ ì”¨ê°€ íë¦°ê²ƒ ê°™ì•„ìš”", 1),
        ("ì´ë²ˆ ì£¼ë§ì—ëŠ” ì§‘ì—ì„œ ì‰´ ì˜ˆì •ì´ì—ìš”", 1),
        ("ì˜¤ëŠ˜ ì ì‹¬ì€ í‰ì†Œì²˜ëŸ¼ íšŒì‚¬ ê·¼ì²˜ ì‹ë‹¹ì—ì„œ ë¨¹ì—ˆì–´ìš”", 1),
        ("ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤", 1),
        ("ë²„ìŠ¤ë¥¼ íƒ€ê³  ì¶œê·¼í–ˆì–´ìš”", 1),
        ("ë‚´ì¼ íšŒì˜ê°€ ìˆë‹¤ê³  í•©ë‹ˆë‹¤", 1),
        ("ì»¤í”¼ë¥¼ ë§ˆì‹œë©´ì„œ ì¼í•˜ê³  ìˆì–´ìš”", 1),
        ("ì´ë²ˆ ë‹¬ íšŒì˜ëŠ” ì˜¨ë¼ì¸ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤", 1),
        ("ìƒˆë¡œìš´ ë™ë£Œê°€ ì…ì‚¬í–ˆë‹¤ê³  í•´ìš”", 1),
        ("ë‹¤ìŒ ì£¼ì— ì¶œì¥ì´ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤", 1),
        ("ì˜¤ëŠ˜ ì—…ë¬´ ë³´ê³ ì„œë¥¼ ì‘ì„±í–ˆì–´ìš”", 1),
        ("ë‚´ì¼ì€ í‰ì†Œë³´ë‹¤ ì¼ì° ì¶œê·¼í•´ì•¼ í•´ìš”", 1),
        ("ì£¼ë§ì— ì¥ì„ ë³´ëŸ¬ ë§ˆíŠ¸ì— ê°ˆ ì˜ˆì •ì´ì—ìš”", 1),
        ("ì˜¤ëŠ˜ ì €ë…ì—ëŠ” ì§‘ì—ì„œ ìš”ë¦¬ë¥¼ í•´ë¨¹ì„ ê±°ì˜ˆìš”", 1),
        ("ì´ë²ˆ ì£¼ëŠ” í‰ì†Œì™€ ë¹„ìŠ·í•˜ê²Œ ì§€ë‚˜ê°”ë„¤ìš”", 1),
        ("ìƒˆë¡œìš´ ì—…ë¬´ ì‹œìŠ¤í…œì„ ë°°ìš°ê³  ìˆìŠµë‹ˆë‹¤", 1),
        ("ì˜¤í›„ì— íŒ€ ë¯¸íŒ…ì´ ìˆìŠµë‹ˆë‹¤", 1),
        ("ì´ë©”ì¼ì„ í™•ì¸í•˜ê³  ë‹µì¥ì„ ë³´ëƒˆì–´ìš”", 1),
        ("ë‚´ì¼ ì¼ì •ì„ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤", 1),
        ("í”„ë¦°í„°ë¡œ ìë£Œë¥¼ ì¶œë ¥í–ˆìŠµë‹ˆë‹¤", 1)
    ]

class DeepEmotionAnalyzer:
    def __init__(self):
        # ë°ì´í„° ì €ì¥ ê²½ë¡œ
        self.data_dir = "emotion_analyzer_data"
        self.vocab_path = os.path.join(self.data_dir, "vocab.json")
        self.model_path = os.path.join(self.data_dir, "model.pth")
        self.training_data_path = os.path.join(self.data_dir, "training_data.pkl")
        
        # ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ ì´ˆê¸°í™”
        self.emotion_keywords = {
            'positive': ['ì¢‹ì•„', 'í–‰ë³µ', 'ê¸°ì˜', 'ê°ì‚¬', 'ì¶•í•˜', 'ì‚¬ë‘', 'ì¦ê²', 'ì‹ ë‚˜', 'í›Œë¥­', 'ë©‹ì§€'],
            'negative': ['ìŠ¬í”„', 'í˜ë“¤', 'ì•„í”„', 'ì‹«ì–´', 'ë¯¸ì•ˆ', 'ì†ìƒ', 'í™”ë‚˜', 'ê´´ë¡­', 'ì‹¤ë§', 'í›„íšŒ'],
            'neutral': ['ë³´í†µ', 'í‰ë²”', 'ì¼ë°˜', 'ë³´í¸', 'ë¬´ë‚œ', 'ì ë‹¹', 'ë³´í¸', 'ì¤‘ê°„', 'ê·¸ì €', 'ë‹´ë‹´']
        }
        
        os.makedirs(self.data_dir, exist_ok=True)
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì •
        self.vocab_size = 8000  # ì–´íœ˜ í¬ê¸° ì„¤ì •
        self.embedding_dim = 200  # ì„ë² ë”© ì°¨ì› ì„¤ì •
        self.hidden_dim = 128  # ì€ë‹‰ì¸µ ì°¨ì› ì„¤ì •
        self.output_dim = 3
        
        self.okt = Okt()
        
        self.load_vocab()
        self.load_training_data()
        self.initialize_model()
        self.setup_gui()

    def load_vocab(self):
        """ì–´íœ˜ ì‚¬ì „ ë¡œë“œ"""
        try:
            if os.path.exists(self.vocab_path):
                with open(self.vocab_path, 'r', encoding='utf-8') as f:
                    self.word_to_idx = json.load(f)
                    self.idx_to_word = {v: k for k, v in self.word_to_idx.items()}
                    print("ì–´íœ˜ ì‚¬ì „ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            else:
                self.word_to_idx = {'<PAD>': 0, '<UNK>': 1}
                self.idx_to_word = {0: '<PAD>', 1: '<UNK>'}
                print("ìƒˆë¡œìš´ ì–´íœ˜ ì‚¬ì „ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì–´íœ˜ ì‚¬ì „ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            self.word_to_idx = {'<PAD>': 0, '<UNK>': 1}
            self.idx_to_word = {0: '<PAD>', 1: '<UNK>'}

    def save_vocab(self):
        """ì–´íœ˜ ì‚¬ì „ ì €ì¥"""
        try:
            with open(self.vocab_path, 'w', encoding='utf-8') as f:
                json.dump(self.word_to_idx, f, ensure_ascii=False, indent=2)
                print("ì–´íœ˜ ì‚¬ì „ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì–´íœ˜ ì‚¬ì „ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    def load_training_data(self):
        """í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(self.training_data_path):
                with open(self.training_data_path, 'rb') as f:
                    self.train_data = pickle.load(f)
                    print(f"í•™ìŠµ ë°ì´í„° {len(self.train_data)}ê°œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            else:
                self.train_data = []
                # ì´ˆê¸° í•™ìŠµ ë°ì´í„° ì¶”ê°€
                self.train_data.extend(load_initial_training_data())
                self.save_training_data()
                print(f"ì´ˆê¸° í•™ìŠµ ë°ì´í„° {len(self.train_data)}ê°œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"í•™ìŠµ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            self.train_data = []

    def save_training_data(self):
        """í•™ìŠµ ë°ì´í„° ì €ì¥"""
        try:
            with open(self.training_data_path, 'wb') as f:
                pickle.dump(self.train_data, f)
                print("í•™ìŠµ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"í•™ìŠµ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    def save_model(self):
        """ëª¨ë¸ ì €ì¥"""
        try:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'vocab_size': self.vocab_size,
                'embedding_dim': self.embedding_dim,
                'hidden_dim': self.hidden_dim,
                'output_dim': self.output_dim
            }, self.model_path)
            print("ëª¨ë¸ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            
    def initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™” ë˜ëŠ” ë¡œë“œ"""
        try:
            if os.path.exists(self.model_path):
                # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ
                checkpoint = torch.load(self.model_path)
                self.model = EmotionAnalysisModel(
                    checkpoint['vocab_size'],
                    checkpoint['embedding_dim'],
                    checkpoint['hidden_dim'],
                    checkpoint['output_dim']
                )
                self.model.load_state_dict(checkpoint['model_state_dict'])
                print("ê¸°ì¡´ ëª¨ë¸ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            else:
                # ìƒˆ ëª¨ë¸ ì´ˆê¸°í™”
                self.model = EmotionAnalysisModel(
                    self.vocab_size,
                    self.embedding_dim,
                    self.hidden_dim,
                    self.output_dim
                )
                print("ìƒˆë¡œìš´ ëª¨ë¸ì„ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
                
            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.model.eval()
            
            # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° GPUë¡œ ì´ë™ //CUDA ì„¤ì¹˜ ì•ˆ ëì„ ê²½ìš° CPUë¡œë¡œ
            if torch.cuda.is_available():
                self.model = self.model.cuda()
                print("GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                print("CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ê¸°ì¡´ íŒŒì¼ ì—†ì„ ì‹œ ìƒˆ ëª¨ë¸ ìƒì„±
            self.model = EmotionAnalysisModel(
                self.vocab_size,
                self.embedding_dim,
                self.hidden_dim,
                self.output_dim
            )
            print("ì˜¤ë¥˜ë¡œ ì¸í•´ ìƒˆ ëª¨ë¸ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    def get_device(self):
        """í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
        if torch.cuda.is_available():
            return torch.device('cuda')
        return torch.device('cpu')

    def move_to_device(self, tensor):
        """í…ì„œë¥¼ ì ì ˆí•œ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™"""
        device = self.get_device()
        return tensor.to(device)
    
    def improved_preprocess_text(self, text):
        """í–¥ìƒëœ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        text = text.lower()
        text = re.sub(r'[^ê°€-í£a-z\s]', ' ', text)
        
        # í˜•íƒœì†Œ ë¶„ì„
        morphs = self.okt.morphs(text)
        
        # ê°ì • í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ë°˜ì˜
        weighted_morphs = []
        for morph in morphs:
            weight = 1.0
            
            # ê°ì • í‚¤ì›Œë“œì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
            if any(keyword in morph for keyword in self.emotion_keywords['positive']):
                weight = 1.5
            elif any(keyword in morph for keyword in self.emotion_keywords['negative']):
                weight = 1.5
            elif any(keyword in morph for keyword in self.emotion_keywords['neutral']):
                weight = 1.2
                
            # ë‹¨ì–´ ì¸ë±ìŠ¤ ë³€í™˜
            if morph not in self.word_to_idx and len(self.word_to_idx) < self.vocab_size:
                self.word_to_idx[morph] = len(self.word_to_idx)
                self.idx_to_word[self.word_to_idx[morph]] = morph
            
            idx = self.word_to_idx.get(morph, self.word_to_idx['<UNK>'])
            weighted_morphs.extend([idx] * int(weight))
        
        # ë™ì  íŒ¨ë”© ì ìš©
        max_length = 100
        if len(weighted_morphs) < max_length:
            weighted_morphs = weighted_morphs + [0] * (max_length - len(weighted_morphs))
        else:
            weighted_morphs = weighted_morphs[:max_length]
        
        return torch.tensor(weighted_morphs).unsqueeze(0)

    def train_model(self):
        """ì…ë ¥ëœ ëª¨ë¸ í•™ìŠµ"""
        if len(self.train_data) < 5:
            self.status_var.set("ìµœì†Œ 5ê°œì˜ í•™ìŠµ ì˜ˆì œê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return
        
        self.status_var.set("í•™ìŠµ ì¤‘...")
        self.window.update()
        
        try:
            # ë°ì´í„° ì¤€ë¹„
            X = []
            y = []
            for text, label in self.train_data:
                input_tensor = self.improved_preprocess_text(text)
                X.append(input_tensor)
                y.append(label)
            
            X = torch.cat(X)
            y = torch.tensor(y)
            
            # ë°ì´í„°ì…‹ ìƒì„±
            dataset = torch.utils.data.TensorDataset(X, y)
            batch_size = min(32, len(dataset))
            dataloader = torch.utils.data.DataLoader(
                dataset,
                batch_size=batch_size,
                shuffle=True
            )
            
            # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ë° ì ìš©
            class_counts = torch.bincount(y, minlength=3)
            weights = 1.0 / class_counts.float()
            weights = weights / weights.sum()
            weights = weights * torch.tensor([1.5, 1.0, 1.2])  # ê¸ì •, ì¤‘ë¦½, ë¶€ì • í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¡°ì •
            
            criterion = nn.CrossEntropyLoss(weight=weights)
            
            # ìµœì í™”ê¸° ì„¤ì •
            optimizer = optim.AdamW(
                self.model.parameters(),
                lr=0.001,
                weight_decay=0.001,
                betas=(0.9, 0.999)
            )
            
            # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                optimizer,
                mode='min',
                factor=0.5,
                patience=5,
                verbose=True
            )
            
            # í•™ìŠµ
            best_loss = float('inf')
            patience = 0
            max_patience = 15  # Early stopping ì„¤ì •
            
            for epoch in range(150):  # ì—í­ ìˆ˜ ì¦ê°€
                self.model.train()
                total_loss = 0
                predictions = []
                true_labels = []
                
                for batch_X, batch_y in dataloader:
                    optimizer.zero_grad()
                    outputs = self.model(batch_X)
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    
                    # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                    
                    total_loss += loss.item()
                    _, predicted = outputs.max(1)
                    predictions.extend(predicted.tolist())
                    true_labels.extend(batch_y.tolist())
                
                # í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°
                precision, recall, f1, _ = precision_recall_fscore_support(
                    true_labels,
                    predictions,
                    average=None,
                    labels=[0, 1, 2]
                )
                
                # ê²€ì¦
                self.model.eval()
                with torch.no_grad():
                    val_outputs = self.model(X)
                    val_loss = criterion(val_outputs, y)
                    val_acc = (val_outputs.argmax(1) == y).float().mean()
                
                # í•™ìŠµë¥  ì¡°ì •
                scheduler.step(val_loss)
                
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                epoch_loss = total_loss / len(dataloader)
                status_msg = (
                    f"Epoch {epoch+1}/150 | Loss: {epoch_loss:.4f} | "
                    f"Val Acc: {val_acc:.2f} | F1: {f1.mean():.2f}"
                )
                self.status_var.set(status_msg)
                self.window.update()
                
                # Early stopping ê²€ì‚¬
                if val_loss < best_loss:
                    best_loss = val_loss
                    self.save_model()
                    patience = 0
                else:
                    patience += 1
                    if patience >= max_patience:
                        break
            
            self.status_var.set("í•™ìŠµ ì™„ë£Œ!")
            
        except Exception as e:
            self.status_var.set(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {e}")

    def analyze_emotion(self, text):
        """ê°ì • ë¶„ì„"""
        try:
            input_tensor = self.improved_preprocess_text(text)
            
            with torch.no_grad():
                self.model.eval()
                outputs = self.model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                
                # ê°ì • í‚¤ì›Œë“œ ê¸°ë°˜ ë³´ì •
                keyword_scores = {
                    'positive': 0,
                    'negative': 0,
                    'neutral': 0
                }
                
                # í…ìŠ¤íŠ¸ì—ì„œ ê°ì • í‚¤ì›Œë“œ ê²€ì¶œ
                for emotion, keywords in self.emotion_keywords.items():
                    for keyword in keywords:
                        if keyword in text:
                            keyword_scores[emotion] += 0.1
                
                # ìµœì¢… í™•ë¥  ê³„ì‚°
                probs = probabilities[0].tolist()
                probs[0] += keyword_scores['positive']  # ê¸ì •
                probs[1] += keyword_scores['neutral']   # ì¤‘ë¦½
                probs[2] += keyword_scores['negative']  # ë¶€ì •
                
                # ì •ê·œí™”
                total = sum(probs)
                probs = [p/total for p in probs]
                
                emotions = {
                    "ê¸ì •": (probs[0], "ğŸ˜Š"),
                    "ì¤‘ë¦½": (probs[1], "ğŸ˜"),
                    "ë¶€ì •": (probs[2], "ğŸ˜¢")
                }
                
                # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ê°ì • ì„ íƒ
                emotion, (prob, emoji) = max(emotions.items(), key=lambda x: x[1][0])
                
                # ìƒì„¸ í™•ë¥  ì¶œë ¥
                detail_info = " | ".join([f"{e}: {p:.1%}" for e, (p, _) in emotions.items()])
                
                # ì‹ ë¢°ë„ ìˆ˜ì¤€ ì¶”ê°€
                confidence = max(probs)
                confidence_level = "ë†’ìŒ" if confidence > 0.6 else "ì¤‘ê°„" if confidence > 0.4 else "ë‚®ìŒ"
                
                return f"{emotion}ì ì¸ ê°ì •ì´ ëŠê»´ì ¸ìš” {emoji}\n[ì‹ ë¢°ë„ {confidence_level} | {detail_info}]"
            
        except Exception as e:
            return f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    # GUI ê´€ë ¨ ë©”ì„œë“œ
    def setup_gui(self):
        """GUI ì„¤ì •"""
        self.window = tk.Tk()
        self.window.title("ê°ì • ë¶„ì„ ì±„íŒ…")
        self.window.geometry("500x700")
        self.window.configure(bg='#BACEE0')  # ë©”ì¸ ìœˆë„ìš° ë°°ê²½ìƒ‰
        
        style = ttk.Style()
        style.configure("Chat.TFrame", background="#BACEE0")
        style.configure("Controls.TFrame", background="#BACEE0")
        style.configure("Controls.TLabelframe", background="#BACEE0")
        style.configure("Controls.TLabel", background="#BACEE0")
        style.configure("Controls.TButton", padding=5)
        
        self.main_frame = ttk.Frame(self.window, style="Chat.TFrame")
        self.main_frame.pack(fill=tk.BOTH, expand=True)
        
        self.setup_chat_area()
        self.setup_input_area()
        self.setup_training_controls()
        self.update_status()

    def setup_chat_area(self):
        """ì±„íŒ… ì˜ì—­ ì„¤ì •"""
        self.chat_frame = ttk.Frame(self.main_frame, style="Chat.TFrame")
        self.chat_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)
        
        self.chat_area = tk.Text(
            self.chat_frame,
            wrap=tk.WORD,
            width=50,
            height=20,
            font=("ë§‘ì€ ê³ ë”•", 10),
            background="#BACEE0",  # ì±„íŒ… ì˜ì—­ ë°°ê²½ìƒ‰
            relief=tk.FLAT,
            padx=10,
            pady=10
        )
        self.chat_area.pack(fill=tk.BOTH, expand=True, side=tk.LEFT)
        
        scrollbar = ttk.Scrollbar(self.chat_frame, orient=tk.VERTICAL, command=self.chat_area.yview)
        scrollbar.pack(fill=tk.Y, side=tk.RIGHT)
        self.chat_area.configure(yscrollcommand=scrollbar.set)
        
        self.chat_area.tag_configure("time", foreground="gray", font=("ë§‘ì€ ê³ ë”•", 8))
        self.chat_area.tag_configure("user_message", font=("ë§‘ì€ ê³ ë”•", 10), justify="right")
        self.chat_area.tag_configure("ai_message", font=("ë§‘ì€ ê³ ë”•", 10), justify="left")
        self.chat_area.tag_configure("system", foreground="blue", font=("ë§‘ì€ ê³ ë”•", 9))
        
        self.chat_area.config(state=tk.DISABLED)

    def setup_input_area(self):
        """ì…ë ¥ ì˜ì—­ ì„¤ì •"""
        input_frame = ttk.Frame(self.main_frame, style="Controls.TFrame")
        input_frame.pack(fill=tk.X, padx=10, pady=5)
        
        self.input_field = ttk.Entry(
            input_frame,
            font=("ë§‘ì€ ê³ ë”•", 10)
        )
        self.input_field.pack(fill=tk.X, side=tk.LEFT, expand=True, padx=(0, 5))
        
        send_button = ttk.Button(
            input_frame,
            text="ì „ì†¡",
            command=self.send_message,
            style="Controls.TButton"
        )
        send_button.pack(side=tk.RIGHT)
        
        self.input_field.bind("<Return>", lambda e: self.send_message())

    def setup_training_controls(self):
        """í•™ìŠµ ì œì–´ ì˜ì—­ ì„¤ì •"""
        training_frame = ttk.LabelFrame(
            self.main_frame,
            text="í•™ìŠµ ì œì–´",
            padding=10,
            style="Controls.TLabelframe"
        )
        training_frame.pack(fill=tk.X, padx=10, pady=5)
        
        # ê°ì • ì„ íƒ
        emotion_frame = ttk.Frame(training_frame, style="Controls.TFrame")
        emotion_frame.pack(fill=tk.X, pady=5)
        
        ttk.Label(
            emotion_frame,
            text="ê°ì •:",
            style="Controls.TLabel"
        ).pack(side=tk.LEFT)
        
        self.emotion_var = tk.StringVar(value="neutral")
        emotions = [("ê¸ì •", "positive"), ("ì¤‘ë¦½", "neutral"), ("ë¶€ì •", "negative")]
        
        for text, value in emotions:
            ttk.Radiobutton(
                emotion_frame,
                text=text,
                value=value,
                variable=self.emotion_var
            ).pack(side=tk.LEFT, padx=5)
        
        # ë²„íŠ¼ í”„ë ˆì„
        button_frame = ttk.Frame(training_frame, style="Controls.TFrame")
        button_frame.pack(fill=tk.X, pady=5)
        
        ttk.Button(
            button_frame,
            text="ì˜ˆì œ ì¶”ê°€",
            command=self.add_training_example,
            style="Controls.TButton"
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            button_frame,
            text="ëª¨ë¸ í•™ìŠµ",
            command=self.train_model,
            style="Controls.TButton"
        ).pack(side=tk.LEFT, padx=5)

        # ëª¨ë¸ ì €ì¥/ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
        ttk.Button(
            button_frame,
            text="ëª¨ë¸ ì €ì¥",
            command=self.save_model,
            style="Controls.TButton"
        ).pack(side=tk.LEFT, padx=5)
        
        # ìƒíƒœ í‘œì‹œ
        self.status_var = tk.StringVar(value="ì¤€ë¹„ë¨")
        self.status_label = ttk.Label(
            training_frame,
            textvariable=self.status_var,
            style="Controls.TLabel"
        )
        self.status_label.pack(fill=tk.X, pady=5)

    def add_message(self, message, is_user=True):
        """ì±„íŒ…ì°½ì— ë©”ì‹œì§€ ì¶”ê°€"""
        self.chat_area.config(state=tk.NORMAL)
        
        current_time = datetime.now().strftime("%H:%M")
        
        if self.chat_area.get("1.0", tk.END).strip():
            self.chat_area.insert(tk.END, "\n\n")

        if is_user:
            self.chat_area.insert(tk.END, " " * 45)
            self.chat_area.insert(tk.END, current_time + "\n", "time")
            self.chat_area.insert(tk.END, " " * 10)
            msg_start = self.chat_area.index("end-1c")
            self.chat_area.insert(tk.END, " " + message + " ", "user_message")
            msg_end = self.chat_area.index("end-1c")
            
            self.chat_area.tag_add("user_bubble", msg_start, msg_end)
            self.chat_area.tag_configure(
                "user_bubble",
                background="#FFEB33",  # ì‚¬ìš©ì ë©”ì‹œì§€ ë°°ê²½ìƒ‰ (ë…¸ë€ìƒ‰)
                borderwidth=1,
                relief="solid",
                lmargin1=20,
                lmargin2=20,
                rmargin=20,
                justify="right"
            )
        else:
            self.chat_area.insert(tk.END, current_time + "\n", "time")
            msg_start = self.chat_area.index("end-1c")
            self.chat_area.insert(tk.END, " " + message + " ", "ai_message")
            msg_end = self.chat_area.index("end-1c")
            
            self.chat_area.tag_add("ai_bubble", msg_start, msg_end)
            self.chat_area.tag_configure(
                "ai_bubble",
                background="#BACEE0",  # AI ë©”ì‹œì§€ ë°°ê²½ìƒ‰
                borderwidth=1,
                relief="solid",
                lmargin1=20,
                lmargin2=20,
                rmargin=20,
                justify="left"
            )

        self.chat_area.see(tk.END)
        self.chat_area.config(state=tk.DISABLED)

    def send_message(self):
        """ë©”ì‹œì§€ ì „ì†¡ ì²˜ë¦¬"""
        message = self.input_field.get().strip()
        if message:
            self.input_field.delete(0, tk.END)
            self.add_message(message)
            
            response = self.analyze_emotion(message)
            self.add_message(response, is_user=False)

    def add_training_example(self):
        """í•™ìŠµ ì˜ˆì œ ì¶”ê°€"""
        text = self.input_field.get().strip()
        emotion = self.emotion_var.get()
        
        if text:
            emotion_to_label = {"positive": 0, "neutral": 1, "negative": 2}
            label = emotion_to_label[emotion]
            
            self.train_data.append((text, label))
            self.save_training_data()
            self.update_status()
            self.input_field.delete(0, tk.END)
            
            self.add_message(f"í•™ìŠµ ì˜ˆì œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. (ê°ì •: {emotion})", is_user=False)

    def update_status(self):
        """ìƒíƒœ ì •ë³´ ì—…ë°ì´íŠ¸"""
        status = f"í•™ìŠµ ë°ì´í„°: {len(self.train_data)}ê°œ | ì–´íœ˜ í¬ê¸°: {len(self.word_to_idx)}ê°œ"
        self.status_var.set(status)

    def run(self):
        """í”„ë¡œê·¸ë¨ ì‹¤í–‰"""
        welcome_msg = (
            "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê°ì • ë¶„ì„ AIì…ë‹ˆë‹¤.\n"
            f"í˜„ì¬ {len(self.train_data)}ê°œì˜ ë°ì´í„°ë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.\n"
            "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì‹œë©´ ê°ì •ì„ ë¶„ì„í•´ë“œë¦´ê²Œìš”! ğŸ˜Š\n"
        )
        self.add_message(welcome_msg, is_user=False)
        
        self.window.mainloop()

# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    try:
        app = DeepEmotionAnalyzer()
        app.run()
    except Exception as e:
        print(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
