import torch  # ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
import torch.nn as nn  # ì‹ ê²½ë§ ëª¨ë“ˆ
import torch.nn.functional as F  # í™œì„±í™” í•¨ìˆ˜ ë° ê¸°íƒ€ ìœ í‹¸ë¦¬í‹°
import torch.optim as optim  # ìµœì í™” ì•Œê³ ë¦¬ì¦˜
import numpy as np  # ìˆ˜í•™ì  ì—°ì‚° ë° ë°°ì—´ ì²˜ë¦¬
import tkinter as tk  # GUI ìƒì„±
from tkinter import ttk, scrolledtext  # Tkinter GUI ìœ„ì ¯
from datetime import datetime  # ë‚ ì§œ ë° ì‹œê°„ ì²˜ë¦¬
from konlpy.tag import Okt  # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸°
import json  # JSON ë°ì´í„° ì²˜ë¦¬
import threading  # ë©€í‹°ìŠ¤ë ˆë”© ì§€ì›
import queue  # ë©€í‹°ìŠ¤ë ˆë”©ì„ ìœ„í•œ í
import os  # íŒŒì¼ ë° ë””ë ‰í„°ë¦¬ ì‘ì—…
import pickle  # ë°ì´í„° ì§ë ¬í™”/ì—­ì§ë ¬í™”
import re  # ì •ê·œ í‘œí˜„ì‹
from sklearn.metrics import precision_recall_fscore_support  # ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­

# ê°ì • ë¶„ì„ ëª¨ë¸ í´ë˜ìŠ¤
class EmotionAnalysisModel(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):
        super().__init__()
        # ì„ë² ë”© ë ˆì´ì–´ ì •ì˜
        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        self.embedding_dropout = nn.Dropout(0.2)  # ë“œë¡­ì•„ì›ƒ: ê³¼ì í•© ë°©ì§€
        
        # CNN ë ˆì´ì–´: ë‹¤ì–‘í•œ í•„í„° í¬ê¸° ì ìš©
        self.conv_layers = nn.ModuleList([
            nn.Conv1d(embedding_dim, hidden_dim, kernel_size=k, padding=k//2)
            for k in [3, 4, 5]  # í•„í„° í¬ê¸°: 3, 4, 5
        ])
        
        # LSTM ë ˆì´ì–´: ì–‘ë°©í–¥ ì²˜ë¦¬
        self.lstm = nn.LSTM(
            hidden_dim * 3,  # CNN ì¶œë ¥ í¬ê¸° (í•„í„° 3ê°œ)
            hidden_dim,  # ì€ë‹‰ì¸µ í¬ê¸°
            num_layers=2,  # LSTM ë ˆì´ì–´ ìˆ˜
            bidirectional=True,  # ì–‘ë°©í–¥ ì²˜ë¦¬
            dropout=0.3,  # ë“œë¡­ì•„ì›ƒ ì ìš©
            batch_first=True  # ì…ë ¥ í˜•íƒœ: (ë°°ì¹˜, ì‹œê°„, íŠ¹ì§•)
        )
        
        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜: ì¤‘ìš”í•œ ë‹¨ì–´ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
        self.attention = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),  # ì–‘ë°©í–¥ LSTM ì¶œë ¥ í¬ê¸°
            nn.LeakyReLU(),  # LeakyReLU í™œì„±í™” í•¨ìˆ˜
            nn.Linear(hidden_dim, 1),  # ìŠ¤ì¹¼ë¼ ê°€ì¤‘ì¹˜ ê³„ì‚°
            nn.Softmax(dim=1)  # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        )
        
        # ì¶œë ¥ ë ˆì´ì–´: ìµœì¢… ê°ì • ì˜ˆì¸¡
        self.dropout = nn.Dropout(0.3)  # ë“œë¡­ì•„ì›ƒ ì¶”ê°€
        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)  # ì€ë‹‰ì¸µ ì—°ê²°
        self.leaky_relu = nn.LeakyReLU()  # LeakyReLU í™œì„±í™” í•¨ìˆ˜
        self.batch_norm = nn.BatchNorm1d(hidden_dim)  # ë°°ì¹˜ ì •ê·œí™”
        self.fc2 = nn.Linear(hidden_dim, output_dim)  # ìµœì¢… ì¶œë ¥ (ê°ì • í´ë˜ìŠ¤)

    def forward(self, text):
        # ì„ë² ë”© ì²˜ë¦¬
        embedded = self.embedding(text)  # ë‹¨ì–´ ì„ë² ë”©
        embedded = self.embedding_dropout(embedded)  # ë“œë¡­ì•„ì›ƒ ì ìš©
        
        # CNN ì²˜ë¦¬
        conv_input = embedded.transpose(1, 2)  # CNN ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
        conv_outputs = []
        for conv in self.conv_layers:
            conv_out = self.leaky_relu(conv(conv_input))  # í™œì„±í™” í•¨ìˆ˜ ì ìš©
            pooled = F.max_pool1d(conv_out, conv_out.shape[2]).squeeze(2)  # ìµœëŒ€ í’€ë§
            conv_outputs.append(pooled)
        
        conv_output = torch.cat(conv_outputs, dim=1)  # CNN ì¶œë ¥ ê²°í•©
        conv_output = conv_output.unsqueeze(1).repeat(1, embedded.size(1), 1)  # LSTM ì…ë ¥ í¬ê¸° ë§ì¶¤
        
        # LSTM ì²˜ë¦¬
        lstm_out, _ = self.lstm(conv_output)
        
        # ì–´í…ì…˜ ì ìš©
        attention_weights = self.attention(lstm_out)  # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        attention_output = torch.bmm(lstm_out.transpose(1, 2), attention_weights).squeeze(-1)  # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¶œë ¥
        
        # ì¶œë ¥ ì²˜ë¦¬
        output = self.dropout(attention_output)  # ë“œë¡­ì•„ì›ƒ ì ìš©
        output = self.fc1(output)  # ì™„ì „ ì—°ê²°ì¸µ
        output = self.leaky_relu(output)  # í™œì„±í™” í•¨ìˆ˜
        output = self.batch_norm(output)  # ë°°ì¹˜ ì •ê·œí™”
        output = self.dropout(output)  # ë“œë¡­ì•„ì›ƒ ì ìš©
        output = self.fc2(output)  # ìµœì¢… ì¶œë ¥
        
        return output

# ì´ˆê¸° í•™ìŠµ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_initial_training_data():
    """ì´ˆê¸° í•™ìŠµ ë°ì´í„°"""
    return [
        # ê¸ì •ì ì¸ ë¬¸ì¥ (20ê°œ)
        ("ì˜¤ëŠ˜ ì •ë§ í–‰ë³µí•œ í•˜ë£¨ì˜€ì–´!", 0),
        ("ì‹œí—˜ ê²°ê³¼ê°€ ë„ˆë¬´ ì¢‹ì•„ì„œ ê¸°ë¶„ì´ ìµœê³ ì•¼!", 0),
        ("ë“œë””ì–´ í”„ë¡œì íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë§ˆì³¤ë‹¤!", 0),
        ("ìƒˆë¡œìš´ ì¹œêµ¬ë¥¼ ì‚¬ê·€ì–´ì„œ ë„ˆë¬´ ì¦ê±°ì›Œ", 0),
        ("ê¸¸ì—ì„œ ìš°ì—°íˆ ì˜› ì¹œêµ¬ë¥¼ ë§Œë‚˜ì„œ ë°˜ê°€ì› ì–´", 0),
        ("ìŠ¹ì§„ ì†Œì‹ì„ ë“¤ì–´ì„œ ì •ë§ ê¸°ì˜ë„¤ìš”", 0),
        ("ì˜¤ëœë§Œì— ê°€ì¡±ë“¤ê³¼ ì¢‹ì€ ì‹œê°„ì„ ë³´ëƒˆì–´ìš”", 0),
        ("ì—´ì‹¬íˆ ì¤€ë¹„í•œ ë°œí‘œê°€ ëŒ€ì„±ê³µì´ì—ˆì–´!", 0),
        ("ì²« ì›”ê¸‰ì„ ë°›ì•„ì„œ ë„ˆë¬´ ì„¤ë ˆìš”", 0),
        ("ìš´ë™ì„ ì‹œì‘í•œ ë’¤ë¡œ ëª¸ì´ ì •ë§ ê±´ê°•í•´ì§„ ê²ƒ ê°™ì•„", 0),
        ("ìƒˆë¡œ ì‚° ì˜·ì´ ë„ˆë¬´ ë§ˆìŒì— ë“¤ì–´", 0),
        ("ì˜¤ëŠ˜ ìš”ë¦¬í•œ ìŒì‹ì´ ì •ë§ ë§›ìˆê²Œ ëì–´", 0),
        ("ì—¬í–‰ ê³„íšì´ ë‹¤ ì§œì—¬ì„œ ë„ˆë¬´ ì‹ ë‚˜!", 0),
        ("ì†Œì›í•˜ë˜ ì¼ì´ ì´ë£¨ì–´ì ¸ì„œ ê°ê²©ìŠ¤ëŸ¬ì›Œìš”", 0),
        ("ë´‰ì‚¬í™œë™ì„ í•˜ê³  ë‚˜ë‹ˆ ë§ˆìŒì´ ë”°ëœ»í•´ì¡Œì–´ìš”", 0),
        ("ì¢‹ì•„í•˜ëŠ” ê°€ìˆ˜ì˜ ì½˜ì„œíŠ¸ í‹°ì¼“ì„ êµ¬í–ˆì–´!", 0),
        ("ë“œë””ì–´ ìê²©ì¦ ì‹œí—˜ì— í•©ê²©í–ˆë‹¤!", 0),
        ("ìƒˆë¡œìš´ ì·¨ë¯¸ë¥¼ ì°¾ì•„ì„œ ë„ˆë¬´ ì¦ê±°ì›Œ", 0),
        ("ì˜¤ëœë§Œì— ë§›ìˆëŠ” ì‹ì‚¬ë¥¼ í–ˆë„¤ìš”", 0),
        ("ì˜ˆìœ ì¹´í˜ë¥¼ ë°œê²¬í•´ì„œ ê¸°ë¶„ì´ ì¢‹ì•„ìš”", 0),

        # ë¶€ì •ì ì¸ ë¬¸ì¥ (20ê°œ)
        ("ì˜¤ëŠ˜ ì •ë§ ìµœì•…ì˜ í•˜ë£¨ì˜€ì–´...", 2),
        ("ì‹œí—˜ì„ ë§ì³ì„œ ë„ˆë¬´ ì†ìƒí•˜ë‹¤", 2),
        ("ì¤‘ìš”í•œ ì•½ì†ì— ì§€ê°í•´ì„œ ë¯¸ì•ˆí•´...", 2),
        ("ì¹œêµ¬ì™€ ì‹¬í•˜ê²Œ ë‹¤í‰ˆì„œ ë§ˆìŒì´ ì•„íŒŒìš”", 2),
        ("í”„ë¡œì íŠ¸ ë§ˆê°ì¼ì— ë§ì¶”ì§€ ëª»í–ˆì–´", 2),
        ("ì‹¤ìˆ˜ë¡œ ì¤‘ìš”í•œ íŒŒì¼ì„ ì‚­ì œí–ˆì–´...", 2),
        ("ëª¸ì´ ì•„íŒŒì„œ ë³‘ì›ì— ê°€ì•¼í•  ê²ƒ ê°™ì•„", 2),
        ("ë©´ì ‘ì—ì„œ ë–¨ì–´ì ¸ì„œ ë„ˆë¬´ ì‹¤ë§ìŠ¤ëŸ¬ì›Œ", 2),
        ("ë¹„ê°€ ì™€ì„œ ê³„íšì´ ë‹¤ ë§ì³ì¡Œì–´", 2),
        ("ì§€ê°‘ì„ ìƒì–´ë²„ë ¤ì„œ ì •ë§ ì†ìƒí•´", 2),
        ("ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë„ˆë¬´ ì‹¬í•´ì„œ í˜ë“¤ì–´ìš”", 2),
        ("ì¹œí•œ ì¹œêµ¬ê°€ ì´ì‚¬ë¥¼ ê°€ì„œ ìŠ¬í¼ìš”", 2),
        ("ì‹¤ìˆ˜ë¡œ í°ì„ ë–¨ì–´ëœ¨ë ¤ì„œ í™”ë©´ì´ ê¹¨ì¡Œì–´", 2),
        ("ë²„ìŠ¤ë¥¼ ë†“ì³ì„œ íšŒì˜ì— ëŠ¦ì—ˆì–´ìš”", 2),
        ("ì¢‹ì•„í•˜ëŠ” ìŒì‹ì ì´ ë¬¸ì„ ë‹«ì•˜ì–´ìš”", 2),
        ("ì¤‘ìš”í•œ ë°œí‘œë¥¼ ë§ì³ì„œ ìì±…ê°ì´ ë“¤ì–´ìš”", 2),
        ("ì• ì¸ê³¼ í—¤ì–´ì ¸ì„œ ë„ˆë¬´ í˜ë“¤ì–´ìš”", 2),
        ("ì§‘ì—ì„œ í‚¤ìš°ë˜ ë°˜ë ¤ë™ë¬¼ì´ ì•„íŒŒìš”", 2),
        ("ì›”ê¸‰ì´ ìƒê°ë³´ë‹¤ ë„ˆë¬´ ì ì–´ì„œ ì‹¤ë§í–ˆì–´ìš”", 2),
        ("íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ë¬´ì„ìŠ¹ì°¨í•˜ëŠ” ë™ë£Œ ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„ìš”", 2),

        # ì¤‘ë¦½ì ì¸ ë¬¸ì¥ (20ê°œ)
        ("ì˜¤ëŠ˜ ë‚ ì”¨ê°€ íë¦°ê²ƒ ê°™ì•„ìš”", 1),
        ("ì´ë²ˆ ì£¼ë§ì—ëŠ” ì§‘ì—ì„œ ì‰´ ì˜ˆì •ì´ì—ìš”", 1),
        ("ì˜¤ëŠ˜ ì ì‹¬ì€ í‰ì†Œì²˜ëŸ¼ íšŒì‚¬ ê·¼ì²˜ ì‹ë‹¹ì—ì„œ ë¨¹ì—ˆì–´ìš”", 1),
        ("ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤", 1),
        ("ë²„ìŠ¤ë¥¼ íƒ€ê³  ì¶œê·¼í–ˆì–´ìš”", 1),
        ("ë‚´ì¼ íšŒì˜ê°€ ìˆë‹¤ê³  í•©ë‹ˆë‹¤", 1),
        ("ì»¤í”¼ë¥¼ ë§ˆì‹œë©´ì„œ ì¼í•˜ê³  ìˆì–´ìš”", 1),
        ("ì´ë²ˆ ë‹¬ íšŒì˜ëŠ” ì˜¨ë¼ì¸ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤", 1),
        ("ìƒˆë¡œìš´ ë™ë£Œê°€ ì…ì‚¬í–ˆë‹¤ê³  í•´ìš”", 1),
        ("ë‹¤ìŒ ì£¼ì— ì¶œì¥ì´ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤", 1),
        ("ì˜¤ëŠ˜ ì—…ë¬´ ë³´ê³ ì„œë¥¼ ì‘ì„±í–ˆì–´ìš”", 1),
        ("ë‚´ì¼ì€ í‰ì†Œë³´ë‹¤ ì¼ì° ì¶œê·¼í•´ì•¼ í•´ìš”", 1),
        ("ì£¼ë§ì— ì¥ì„ ë³´ëŸ¬ ë§ˆíŠ¸ì— ê°ˆ ì˜ˆì •ì´ì—ìš”", 1),
        ("ì˜¤ëŠ˜ ì €ë…ì—ëŠ” ì§‘ì—ì„œ ìš”ë¦¬ë¥¼ í•´ë¨¹ì„ ê±°ì˜ˆìš”", 1),
        ("ì´ë²ˆ ì£¼ëŠ” í‰ì†Œì™€ ë¹„ìŠ·í•˜ê²Œ ì§€ë‚˜ê°”ë„¤ìš”", 1),
        ("ìƒˆë¡œìš´ ì—…ë¬´ ì‹œìŠ¤í…œì„ ë°°ìš°ê³  ìˆìŠµë‹ˆë‹¤", 1),
        ("ì˜¤í›„ì— íŒ€ ë¯¸íŒ…ì´ ìˆìŠµë‹ˆë‹¤", 1),
        ("ì´ë©”ì¼ì„ í™•ì¸í•˜ê³  ë‹µì¥ì„ ë³´ëƒˆì–´ìš”", 1),
        ("ë‚´ì¼ ì¼ì •ì„ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤", 1),
        ("í”„ë¦°í„°ë¡œ ìë£Œë¥¼ ì¶œë ¥í–ˆìŠµë‹ˆë‹¤", 1)
    ]

# ê°ì • ë¶„ì„ í”„ë¡œê·¸ë¨ì˜ í•µì‹¬ í´ë˜ìŠ¤
class DeepEmotionAnalyzer:
    def __init__(self):
        # ë°ì´í„° ì €ì¥ ê²½ë¡œ ì„¤ì •
        self.data_dir = "emotion_analyzer_data"  # ë°ì´í„° ì €ì¥ ë””ë ‰í„°ë¦¬
        self.vocab_path = os.path.join(self.data_dir, "vocab.json")  # ì–´íœ˜ ì‚¬ì „ ê²½ë¡œ
        self.model_path = os.path.join(self.data_dir, "model.pth")  # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        self.training_data_path = os.path.join(self.data_dir, "training_data.pkl")  # í•™ìŠµ ë°ì´í„° ê²½ë¡œ
        
        # ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ ì´ˆê¸°í™”
        self.emotion_keywords = {
            'positive': ['ì¢‹ì•„', 'í–‰ë³µ', 'ê¸°ì˜', 'ê°ì‚¬', 'ì¶•í•˜', 'ì‚¬ë‘', 'ì¦ê²', 'ì‹ ë‚˜', 'í›Œë¥­', 'ë©‹ì§€'],
            'negative': ['ìŠ¬í”„', 'í˜ë“¤', 'ì•„í”„', 'ì‹«ì–´', 'ë¯¸ì•ˆ', 'ì†ìƒ', 'í™”ë‚˜', 'ê´´ë¡­', 'ì‹¤ë§', 'í›„íšŒ'],
            'neutral': ['ë³´í†µ', 'í‰ë²”', 'ì¼ë°˜', 'ë¬´ë‚œ', 'ì¤‘ê°„', 'ê·¸ì €', 'ë‹´ë‹´']
        }
        
        # ë°ì´í„° ë””ë ‰í„°ë¦¬ ìƒì„±
        os.makedirs(self.data_dir, exist_ok=True)
        
        # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
        self.vocab_size = 8000  # ì–´íœ˜ í¬ê¸°
        self.embedding_dim = 200  # ì„ë² ë”© ì°¨ì› ìˆ˜
        self.hidden_dim = 128  # ì€ë‹‰ì¸µ ì°¨ì› ìˆ˜
        self.output_dim = 3  # ì¶œë ¥ ì°¨ì› ìˆ˜ (ê¸ì •, ì¤‘ë¦½, ë¶€ì •)
        
        self.okt = Okt()  # í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        # ì–´íœ˜ ì‚¬ì „ ë° í•™ìŠµ ë°ì´í„° ë¡œë“œ
        self.load_vocab()
        self.load_training_data()
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.initialize_model()
        
        # GUI ì´ˆê¸°í™”
        self.setup_gui()

    def load_vocab(self):
        """ì–´íœ˜ ì‚¬ì „ì„ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±"""
        try:
            if os.path.exists(self.vocab_path):
                with open(self.vocab_path, 'r', encoding='utf-8') as f:
                    self.word_to_idx = json.load(f)  # ë‹¨ì–´ -> ì¸ë±ìŠ¤ ë§¤í•‘
                    self.idx_to_word = {v: k for k, v in self.word_to_idx.items()}  # ì¸ë±ìŠ¤ -> ë‹¨ì–´ ë§¤í•‘
                    print("ì–´íœ˜ ì‚¬ì „ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            else:
                # ì–´íœ˜ ì‚¬ì „ ì´ˆê¸°í™”
                self.word_to_idx = {'<PAD>': 0, '<UNK>': 1}
                self.idx_to_word = {0: '<PAD>', 1: '<UNK>'}
                print("ìƒˆë¡œìš´ ì–´íœ˜ ì‚¬ì „ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì–´íœ˜ ì‚¬ì „ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            self.word_to_idx = {'<PAD>': 0, '<UNK>': 1}
            self.idx_to_word = {0: '<PAD>', 1: '<UNK>'}

    def save_vocab(self):
        """ì–´íœ˜ ì‚¬ì „ì„ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with open(self.vocab_path, 'w', encoding='utf-8') as f:
                json.dump(self.word_to_idx, f, ensure_ascii=False, indent=2)
                print("ì–´íœ˜ ì‚¬ì „ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì–´íœ˜ ì‚¬ì „ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    def load_training_data(self):
        """í•™ìŠµ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ì´ˆê¸°í™”"""
        try:
            if os.path.exists(self.training_data_path):
                with open(self.training_data_path, 'rb') as f:
                    self.train_data = pickle.load(f)
                    print(f"í•™ìŠµ ë°ì´í„° {len(self.train_data)}ê°œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            else:
                # í•™ìŠµ ë°ì´í„° ì´ˆê¸°í™”
                self.train_data = []
                self.train_data.extend(load_initial_training_data())  # ì´ˆê¸° ë°ì´í„° ì¶”ê°€
                self.save_training_data()
                print(f"ì´ˆê¸° í•™ìŠµ ë°ì´í„° {len(self.train_data)}ê°œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"í•™ìŠµ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            self.train_data = []

    def save_training_data(self):
        """í•™ìŠµ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with open(self.training_data_path, 'wb') as f:
                pickle.dump(self.train_data, f)
                print("í•™ìŠµ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"í•™ìŠµ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    def initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™” ë˜ëŠ” ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ"""
        try:
            if os.path.exists(self.model_path):
                # ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
                checkpoint = torch.load(self.model_path)
                self.model = EmotionAnalysisModel(
                    checkpoint['vocab_size'],
                    checkpoint['embedding_dim'],
                    checkpoint['hidden_dim'],
                    checkpoint['output_dim']
                )
                self.model.load_state_dict(checkpoint['model_state_dict'])
                print("ê¸°ì¡´ ëª¨ë¸ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            else:
                # ìƒˆ ëª¨ë¸ ì´ˆê¸°í™”
                self.model = EmotionAnalysisModel(
                    self.vocab_size,
                    self.embedding_dim,
                    self.hidden_dim,
                    self.output_dim
                )
                print("ìƒˆë¡œìš´ ëª¨ë¸ì„ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
                
            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.model.eval()
            
            # GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸
            if torch.cuda.is_available():
                self.model = self.model.cuda()  # ëª¨ë¸ì„ GPUë¡œ ì´ë™
                print("GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                print("CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒˆ ëª¨ë¸ ìƒì„±
            self.model = EmotionAnalysisModel(
                self.vocab_size,
                self.embedding_dim,
                self.hidden_dim,
                self.output_dim
            )
            print("ì˜¤ë¥˜ë¡œ ì¸í•´ ìƒˆ ëª¨ë¸ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    def get_device(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ë°˜í™˜ (GPU ë˜ëŠ” CPU)"""
        return torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    def move_to_device(self, tensor):
        """í…ì„œë¥¼ ë””ë°”ì´ìŠ¤(GPU/CPU)ë¡œ ì´ë™"""
        device = self.get_device()
        return tensor.to(device)

    def improved_preprocess_text(self, text):
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì–´íœ˜ ì‚¬ì „ ì—…ë°ì´íŠ¸"""
        # í…ìŠ¤íŠ¸ ì •ê·œí™” (ì†Œë¬¸ì ë³€í™˜ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±°)
        text = text.lower()
        text = re.sub(r'[^ê°€-í£a-z\s]', ' ', text)
        
        # í˜•íƒœì†Œ ë¶„ì„
        morphs = self.okt.morphs(text)
        
        # í˜•íƒœì†Œì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ì¶”ê°€
        weighted_morphs = []
        for morph in morphs:
            weight = 1.0  # ê¸°ë³¸ ê°€ì¤‘ì¹˜
            
            # ê°ì • í‚¤ì›Œë“œì— ë”°ë¼ ê°€ì¤‘ì¹˜ ì¡°ì •
            if morph in self.emotion_keywords['positive']:
                weight = 1.5
            elif morph in self.emotion_keywords['negative']:
                weight = 1.5
            elif morph in self.emotion_keywords['neutral']:
                weight = 1.2
            
            # ë‹¨ì–´ê°€ ì–´íœ˜ ì‚¬ì „ì— ì—†ìœ¼ë©´ ì¶”ê°€
            if morph not in self.word_to_idx and len(self.word_to_idx) < self.vocab_size:
                self.word_to_idx[morph] = len(self.word_to_idx)
                self.idx_to_word[self.word_to_idx[morph]] = morph
            
            # ì–´íœ˜ ì‚¬ì „ì—ì„œ ë‹¨ì–´ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì˜´
            idx = self.word_to_idx.get(morph, self.word_to_idx['<UNK>'])
            weighted_morphs.extend([idx] * int(weight))
        
        # í…ì„œë¥¼ ê³ ì •ëœ ê¸¸ì´ë¡œ íŒ¨ë”©
        max_length = 100  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
        if len(weighted_morphs) < max_length:
            weighted_morphs = weighted_morphs + [0] * (max_length - len(weighted_morphs))
        else:
            weighted_morphs = weighted_morphs[:max_length]
        
        return torch.tensor(weighted_morphs).unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

    def train_model(self):
        """ëª¨ë¸ í•™ìŠµì„ ìˆ˜í–‰"""
        if len(self.train_data) < 5:
            # í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ì•Œë¦¼
            self.status_var.set("ìµœì†Œ 5ê°œì˜ í•™ìŠµ ì˜ˆì œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        self.status_var.set("í•™ìŠµ ì¤‘...")  # ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
        self.window.update()  # GUI ì—…ë°ì´íŠ¸
        
        try:
            # ë°ì´í„° ì¤€ë¹„
            X = []
            y = []
            for text, label in self.train_data:
                input_tensor = self.improved_preprocess_text(text)  # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
                X.append(input_tensor)
                y.append(label)
            
            X = torch.cat(X)  # í…ì„œë¡œ ë³€í™˜
            y = torch.tensor(y)  # ë ˆì´ë¸” í…ì„œ ìƒì„±
            
            # ë°ì´í„°ì…‹ ìƒì„±
            dataset = torch.utils.data.TensorDataset(X, y)
            batch_size = min(32, len(dataset))  # ë°°ì¹˜ í¬ê¸° ì„¤ì •
            dataloader = torch.utils.data.DataLoader(
                dataset,
                batch_size=batch_size,
                shuffle=True  # ë°ì´í„° ì„ê¸°
            )
            
            # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
            class_counts = torch.bincount(y, minlength=3)  # í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ê³„ì‚°
            weights = 1.0 / class_counts.float()  # ê°€ì¤‘ì¹˜ ê³„ì‚°
            weights = weights / weights.sum()  # ì •ê·œí™”
            criterion = nn.CrossEntropyLoss(weight=weights)  # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì†ì‹¤ í•¨ìˆ˜
            
            # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
            optimizer = optim.AdamW(
                self.model.parameters(),
                lr=0.001,  # í•™ìŠµë¥ 
                weight_decay=0.001  # ê°€ì¤‘ì¹˜ ê°ì‡ 
            )
            
            # í•™ìŠµ
            for epoch in range(20):  # ì—í­ ìˆ˜
                self.model.train()  # ëª¨ë¸ í•™ìŠµ ëª¨ë“œ ì „í™˜
                total_loss = 0
                
                for batch_X, batch_y in dataloader:
                    optimizer.zero_grad()  # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
                    outputs = self.model(batch_X)  # ëª¨ë¸ ì˜ˆì¸¡
                    loss = criterion(outputs, batch_y)  # ì†ì‹¤ ê³„ì‚°
                    loss.backward()  # ì—­ì „íŒŒ
                    optimizer.step()  # ë§¤ê°œë³€ìˆ˜ ì—…ë°ì´íŠ¸
                    total_loss += loss.item()  # ì†ì‹¤ ëˆ„ì 
                
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                status_msg = f"Epoch {epoch + 1}/20 | Loss: {total_loss / len(dataloader):.4f}"
                self.status_var.set(status_msg)
                self.window.update()
            
            self.save_model()  # í•™ìŠµëœ ëª¨ë¸ ì €ì¥
            self.status_var.set("í•™ìŠµ ì™„ë£Œ!")
        
        except Exception as e:
            self.status_var.set(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {e}")

    def analyze_emotion(self, text):
        """ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„"""
        try:
            input_tensor = self.improved_preprocess_text(text)  # ì…ë ¥ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            
            with torch.no_grad():
                self.model.eval()  # ëª¨ë¸ í‰ê°€ ëª¨ë“œ
                outputs = self.model(input_tensor)  # ê°ì • ì˜ˆì¸¡
                probabilities = torch.softmax(outputs, dim=1)  # í™•ë¥  ê³„ì‚°
                
                # ê°ì •ë³„ í™•ë¥ 
                positive_prob = probabilities[0, 0].item()
                neutral_prob = probabilities[0, 1].item()
                negative_prob = probabilities[0, 2].item()
                
                # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ê°ì • ì„ íƒ
                probs = [positive_prob, neutral_prob, negative_prob]
                labels = ["ê¸ì • ğŸ˜Š", "ì¤‘ë¦½ ğŸ˜", "ë¶€ì • ğŸ˜¢"]
                max_index = np.argmax(probs)
                confidence = probs[max_index]
                emotion = labels[max_index]
                
                # ì‹ ë¢°ë„ì— ë”°ë¼ ë ˆë²¨ í‘œì‹œ
                confidence_level = (
                    "ë†’ìŒ" if confidence > 0.6 else "ì¤‘ê°„" if confidence > 0.4 else "ë‚®ìŒ"
                )
                
                return f"{emotion} (ì‹ ë¢°ë„: {confidence_level}, ê¸ì •: {positive_prob:.2f}, ì¤‘ë¦½: {neutral_prob:.2f}, ë¶€ì •: {negative_prob:.2f})"
        
        except Exception as e:
            return f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    def setup_gui(self):
        """GUI ì„¤ì •"""
        self.window = tk.Tk()  # Tkinter ìœˆë„ìš° ìƒì„±
        self.window.title("ê°ì • ë¶„ì„ í”„ë¡œê·¸ë¨")  # ì°½ ì œëª©
        self.window.geometry("500x600")  # ì°½ í¬ê¸° ì„¤ì •
        
        # ë©”ì¸ í”„ë ˆì„ ì„¤ì •
        main_frame = ttk.Frame(self.window)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # ì±„íŒ… ì˜ì—­ ì„¤ì •
        self.chat_area = scrolledtext.ScrolledText(
            main_frame, wrap=tk.WORD, font=("ë§‘ì€ ê³ ë”•", 12), height=20
        )
        self.chat_area.pack(fill=tk.BOTH, expand=True)
        self.chat_area.config(state=tk.DISABLED)  # í¸ì§‘ ë¶ˆê°€
        
        # ì…ë ¥ ì˜ì—­ ì„¤ì •
        input_frame = ttk.Frame(main_frame)
        input_frame.pack(fill=tk.X, pady=5)
        
        self.input_field = ttk.Entry(input_frame, font=("ë§‘ì€ ê³ ë”•", 12))
        self.input_field.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))
        self.input_field.bind("<Return>", lambda e: self.send_message())  # ì—”í„° í‚¤ ì´ë²¤íŠ¸
        
        send_button = ttk.Button(input_frame, text="ì „ì†¡", command=self.send_message)
        send_button.pack(side=tk.RIGHT)
        
        # ìƒíƒœ í‘œì‹œ ë¼ë²¨
        self.status_var = tk.StringVar(value="ìƒíƒœ: ì¤€ë¹„ë¨")
        status_label = ttk.Label(main_frame, textvariable=self.status_var, anchor=tk.W)
        status_label.pack(fill=tk.X, pady=5)

    def send_message(self):
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì „ì†¡ ë° ê°ì • ë¶„ì„"""
        message = self.input_field.get().strip()
        if message:
            # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”
            self.input_field.delete(0, tk.END)
            self.add_message(message, is_user=True)  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            
            response = self.analyze_emotion(message)  # ê°ì • ë¶„ì„ ê²°ê³¼
            self.add_message(response, is_user=False)  # AI ì‘ë‹µ ì¶”ê°€

    def add_message(self, message, is_user):
        """ì±„íŒ…ì°½ì— ë©”ì‹œì§€ ì¶”ê°€"""
        self.chat_area.config(state=tk.NORMAL)  # ì±„íŒ…ì°½ í¸ì§‘ ê°€ëŠ¥ ì„¤ì •
        current_time = datetime.now().strftime("%H:%M")  # í˜„ì¬ ì‹œê°„
        
        if is_user:
            # ì‚¬ìš©ì ë©”ì‹œì§€ í¬ë§·
            self.chat_area.insert(tk.END, f"ì‚¬ìš©ì ({current_time}): {message}\n")
        else:
            # AI ë©”ì‹œì§€ í¬ë§·
            self.chat_area.insert(tk.END, f"AI ({current_time}): {message}\n")
        
        self.chat_area.see(tk.END)  # ì±„íŒ…ì°½ ìŠ¤í¬ë¡¤ ìµœí•˜ë‹¨ìœ¼ë¡œ ì´ë™
        self.chat_area.config(state=tk.DISABLED)  # ì±„íŒ…ì°½ í¸ì§‘ ë¶ˆê°€ ì„¤ì •

    def run(self):
        """í”„ë¡œê·¸ë¨ ì‹¤í–‰"""
        welcome_msg = (
            "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê°ì • ë¶„ì„ AIì…ë‹ˆë‹¤.\n"
            "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì‹œë©´ ê°ì •ì„ ë¶„ì„í•´ ë“œë¦´ê²Œìš” ğŸ˜Š"
        )
        self.add_message(welcome_msg, is_user=False)  # í™˜ì˜ ë©”ì‹œì§€
        self.window.mainloop()  # GUI ë£¨í”„ ì‹¤í–‰

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    try:
        app = DeepEmotionAnalyzer()
        app.run()
    except Exception as e:
        print(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
